library(MASS)
library(leaps)
summary(Boston)
attach(Boston)
dim(Boston)
set.seed(1)
train = sample(seq(506), 338, replace = FALSE)
train
regfit.full = regsubsets(crim~., data = Boston[train,], nvmax = 13)
reg.summary = summary(regfit.full)
plot(reg.summary$cp, xlab = "Number of Variables" , ylab = "Cp") #Graph of CP against number of vars
which.min(reg.summary$cp)
val.errors = rep(NA, 13)
regfit.full = regsubsets(crim~., data = Boston[train,], nvmax = 13)
x.test = model.matrix(crim~., data = Boston[train,])
x.test = model.matrix(crim~., data = Boston[-train,])
for(i in 1:13){
coefi = coef(regfit.full, id = i)
pred = x.test[,names(coefi)]%*%coefi
val.errors[i] = mean((Boston$crim[-train,] - pred)^2)
plot(sqrt(val.errors), ylab = "Root MSE", pch =13, type = "b")
plot(sqrt(val.errors), ylab = "Root MSE", pch =13, type = "b")
plot(sqrt(val.errors), ylab = "Root MSE", pch =19, type = "b")
}
rm(list = ls())
library(ISLR)
library(MASS)
library(leaps)
summary(Boston)
attach(Boston)
set.seed(1)
train = sample(seq(506), 338, replace = FALSE)
#best subset
regfit.full = regsubsets(crim~., data = Boston[train,], nvmax = 13)
reg.summary = summary(regfit.full)
plot(reg.summary$cp, xlab = "Number of Variables" , ylab = "Cp") #Graph of CP against number of vars
which.min(reg.summary$cp)
plot(reg.summary$adjr2, xlab = "Number of Variables" , ylab = "adj R^2") #Graph of CP against number of vars
which.max(reg.summary$adjr2)
coef(regfit.full,10)
val.errors = rep(NA, 13)
x.test = model.matrix(crim~., data = Boston[-train,])
for(i in 1:13){
coefi = coef(regfit.full, id = i)
pred = x.test[,names(coefi)]%*%coefi
val.errors[i] = mean((Boston$crim[-train,] - pred)^2)
}
for(i in 1:13){
coefi = coef(regfit.full, id = i)
pred = x.test[,names(coefi)]%*%coefi
val.errors[i] = mean((Boston$crim[-train] - pred)^2)
}
plot(sqrt(val.errors), ylab = "Root MSE", pch =19, type = "b")
which.max(val.errors)
which.min(val.errors)
val.errors[10]
set.seed(11)
folds = sample(rep(1:10),length = nrow(Boston))
folds = sample(rep(1:10,length = nrow(Boston)))
table(folds)
folds
predict.regsubsets = function(object, newdata, id, ...){
from = as.formula(object$call[[2]])
mat = model.matrix((form,newdata))
coefi = coef(object, id=id)
mag[,names(coefi)]%*%coefi
}
predict.regsubsets = function(object, newdata, id, ...){
from = as.formula(object$call[[2]])
mat = model.matrix(form,newdata)
coefi = coef(object, id=id)
mag[,names(coefi)]%*%coefi
}
cv.errors = matrix(NA,10,13)
#10-fold cross validation
set.seed(11)
folds = sample(rep(1:10,length = nrow(Boston)))
cv.errors = matrix(NA,10,13)
#best subset
for(k in 1:10){
regfit.full = regsubsets(crim~., data = Boston[folds != k,], nvmax = 13)
for(i in 1:13){
pred = predict(regfit.full, Boston[folds==k],id=i)
cv.errors[k,i] = mean((Boston$crim[folds==k] - pred)^2)
}
}
regf
predict.regsubsets = function(object, newdata, id, ...){
form = as.formula(object$call[[2]])
mat = model.matrix(form,newdata)
coefi = coef(object, id=id)
mag[,names(coefi)]%*%coefi
}
#10-fold cross validation
set.seed(11)
folds = sample(rep(1:10,length = nrow(Boston)))
cv.errors = matrix(NA,10,13)
#best subset
for(k in 1:10){
regfit.full = regsubsets(crim~., data = Boston[folds != k,], nvmax = 13)
for(i in 1:13){
pred = predict(regfit.full, Boston[folds==k],id=i)
cv.errors[k,i] = mean((Boston$crim[folds==k] - pred)^2)
}
}
#10-fold cross validation
set.seed(11)
folds = sample(rep(1:10,length = nrow(Boston)))
cv.errors = matrix(NA,10,13)
#best subset
for(k in 1:10){
regfit.full = regsubsets(crim~., data = Boston[folds != k,], nvmax = 13)
for(i in 1:13){
pred = predict(regfit.full, Boston[folds==k,],id=i)
cv.errors[k,i] = mean((Boston$crim[folds==k] - pred)^2)
}
}
predict.regsubsets = function(object, newdata, id, ...){
form = as.formula(object$call[[2]])
mat = model.matrix(form,newdata)
coefi = coef(object, id=id)
mat[,names(coefi)]%*%coefi
}
set.seed(11)
folds = sample(rep(1:10,length = nrow(Boston)))
cv.errors = matrix(NA,10,13)
#best subset
for(k in 1:10){
regfit.full = regsubsets(crim~., data = Boston[folds != k,], nvmax = 13)
for(i in 1:13){
pred = predict(regfit.full, Boston[folds==k,],id=i)
cv.errors[k,i] = mean((Boston$crim[folds==k] - pred)^2)
}
}
View(cv.errors)
rmse.cv = sqrt(apply(cv.er, 2, mean))
rmse.cv = sqrt(apply(cv.errors, 2, mean))
plot(rmse.cv, pch=13, type="b")
rmse.cv[9]
for(k in 1:10){
fwd = regsubsets(crim~., data = Boston[train,], nvmax = 13, method = "forward")
for(i in 1:13){
pred = predict(fwd, Boston[folds==k,],id=i)
cv.errors[k,i] = mean((Boston$crim[folds==k] - pred)^2)
}
}
rmse.cv = sqrt(apply(cv.errors, 2, mean))
plot(rmse.cv, pch=13, type="b")
rmse.cv[9]
rmse.cv[12]
rmse.cv[10]
x = model.matrix(crim~., data = Boston)
y = Boston$crim
lasso = glmnet(x, y, alpha = 1)
plot(lasso, xvar = "lambda", label = TRUE) # checking the coefficients
library(glmnet)
lasso = glmnet(x, y, alpha = 1)
plot(lasso, xvar = "lambda", label = TRUE) # checking the coefficients
set.seed(1)
cv.lasso = cv.glmnet(x, y, alpha=1)
plot(cv.lasso)
bestLambda2 = cv.lasso$lambda.min
bestLambda2
mean((lasso.pred- test$Apps)^2)
lasso.pred = predict(lasso, s= bestLambda2 , type = "coefficients" ,newx = model.matrix(Apps~.-1, data = test))
rmse.cv[10]
?cv.glmnet
cv.lasso = cv.glmnet(x, y, alpha=1, keep = TRUE)
cv.lasso$foldid
cv.lasso$lambda.1se
cv.lasso$cvm
cv.lasso$cvsd
cv.lasso$lambda
train=sample(1:nrow(x), nrow(x)/2)
train=sample(seq(506),338, replace = FALSE)
x = model.matrix(crim~., data = Boston[train,])
x = model.matrix(crim~., data = Boston)
y = Boston$crim
lasso = glmnet(x[train,], y[train,], alpha = 1)
x = model.matrix(crim~., data = Boston)
y = Boston$crim
lasso = glmnet(x[train,], y[train,], alpha = 1)
lasso = glmnet(x[train,], y[train], alpha = 1)
plot(lasso, xvar = "lambda", label = TRUE) # checking the coefficients
set.seed(1)
cv.lasso = cv.glmnet(x, y, alpha=1, keep = TRUE)
plot(cv.lasso)
bestLambda2 = cv.lasso$lambda.min
cv.lasso$
lasso.pred = predict(lasso, s= bestLambda2 , type = "coefficients" ,newx = x[-train,])
mean((lasso.pred- test$Apps)^2)
mean((lasso.pred- Boston$Apps[-train])^2)
mean((lasso.pred- Boston$Apps[-train])^2)
mean((lasso.pred- Boston[-train]$Apps)^2)
Boston[train]
Boston[train,]
Boston[-train,]
mean((lasso.pred- Boston[-train]$crim)^2)
lasso.pred = predict(lasso, s= bestLambda2 , type = "coefficients" ,newx = x[-train,])
mean((lasso.pred- Boston[-train]$crim)^2)
Boston[-train]
Boston[-train,]$crim
mean((lasso.pred- Boston[-train,]$crim)^2)
mean((lasso.pred- x[-train,]$crim)^2)
train=sample(seq(506),338, replace = FALSE)
x = model.matrix(crim~., data = Boston)
y = Boston$crim
lasso = glmnet(x[train,], y[train], alpha = 1)
plot(lasso, xvar = "lambda", label = TRUE) # checking the coefficients
set.seed(1)
cv.lasso = cv.glmnet(x, y, alpha=1, keep = TRUE)
plot(cv.lasso)
bestLambda2 = cv.lasso$lambda.min
lasso.pred = predict(lasso, s= bestLambda2 , type = "coefficients" ,newx = x[-train,])
mean((lasso.pred- x[-train,]$crim)^2)
mean((lasso.pred- y[-train])^2)
lasso.pred
lasso.pred = predict(lasso, s= bestLambda2  ,newx = x[-train,])
mean((lasso.pred- y[-train])^2)
View(lasso.pred)
rm(list = ls())
library(ISLR)
attach(OJ)
train = sample(seq(nrow(OJ)), 800, replace = FALSE)
train
length(train)
require(tree)
install.packages("library")
require(tree)
summary(OJ)
?OJ
treee.oj = tree(Purchase~., data = OJ[train])
install.packages("tree")
require(tree)
treee.oj = tree(Purchase~., data = OJ[train])
treee.oj = tree(Purchase~., data = OJ[train,])
library(ISLR)
?OJ
treee.oj = tree(Purchase~., data = OJ[train,])
summary(treee.oj)
tree.oj = tree(Purchase~., data = OJ[train,]) #fitting a tree molde
summary(tree.oj)
plot(tree.oj)
text(tree.oj, pretty= 0)
tree.oj
set.seed(1)
train = sample(seq(nrow(OJ)), 800, replace = FALSE)
tree.oj = tree(Purchase~., data = OJ[train,]) #fitting a tree molde
summary(tree.oj)
#4. Create a plot of the tree, and interpret the results.
plot(tree.oj)
text(tree.oj, pretty= 0)
treePred = predict(tree.oj, newdata = OJ[-train,], type = "class")
meaan(treePred == OJ[-train,])
mean(treePred == OJ[-train,])
table(treePred, OJ[-train,])
table(treePred, OJ[-train,]$Purchase)
mean(treePred == OJ[-train,]$Purchase)
cv.oj = cv.tree(tree.oj, FUN = prune.misclass) #prune using missclassification
cv.oj
plot(cv.oj)
prune.oj = prune.misclass(tree.oj, best = 5)
prune.oj
plot(prune.oj)
text(prune.oj, pretty = 0)
summary(prune.oj)
prunedPred = predict(prune.oj, newdata = OJ[-train,], type="class")
table(prunedPred, OJ[-train,]$Purchase) #confusion Matrix
mean(prunedPred == OJ[-train,]$Purchase) # test error
table(treePred, OJ[-train,]$Purchase) #confusion Matrix
mean(treePred == OJ[-train,]$Purchase) # test error
library(ISRL)
library(ISLR)
rm(list = ls())
library(ISLR)
attach(Carseats)
?Carseats
train = sample(1:nrow(Carseats),100)
set.seed(20)
train = sample(1:nrow(Carseats),300)
require(tree)
car.tree = tree(Sales~., subset = train)
car.tree = tree(Sales~., data = Carseats[train,])
text(cv.tree, pretty = 0)
text(car.tree, pretty = 0)
text(car.tree, pretty = 0)
plot(car.tree)
text(car.tree, pretty = 0))
text(car.tree, pretty = 0)
summary(car.tree)
predTree  = predict(car.tree, newdata = Carseats[-train,])
mean( (predTree - Carseats[-train,]$Sales)^2 )
cv.carTree = cv.tree(car.tree, FUN = prune.misclass)
cv.carTree = cv.tree(car.tree, FUN = prune.tree)
plot(cv.carTree)
cv.carTree
prune.tree  = prune.tree(cv.carTree, best = 8)
prune.tree  = prune.tree(car.tree, best = 8)
predPrune  = predict(prune.tree, newdata = Carseats[-train,])
mean( (predPrune - Carseats[-train,]$Sales)^2 ) #test MSE
summary(car.tree)
prune.tree
summary(prune.tree)
prune.tree  = prune.tree(car.tree, best = 15)
predPrune  = predict(prune.tree, newdata = Carseats[-train,])
mean( (predPrune - Carseats[-train,]$Sales)^2 ) #test MSE
require(randomForest)
install.packages("randomForest")
require(randomForest)
rf.cars = randomForest(Sales~., data = Carseats[train,])
rf.cars
?Carseats
ncol(Carseats)
bg.cars = randomForest(Sales~., data = Carseats[train,], importance = TRUE, mtry = 11)
bg.cars
bg.cars$importance
bg.cars$importanceSD
bg.pred = predict(bg.cars, newdata = Carseats[-train,])
mean((bg.pred - Carseats[-train,]$Sales)^2)
rf.cars = randomForest(Sales~., data = Carseats[train,], mtry =4 ,importance = TRUE)
rf.cars = randomForest(Sales~., data = Carseats[train,], mtry =4 ,importance = TRUE)
rf.cars$importance
rf.pred = predict(rf.cars, newdata = Carseats[-train,])
mean((rf.pred - Carseats[-train,]$Sales)^2)
mean((rf.pred - Carseats[-train,]$Sales)^2)
library(ISLR)
require(tree)
#install.packages("randomForest")
require(randomForest)
#1. Split the data set into a training set and a test set.
attach(Carseats)
set.seed(20)
train = sample(1:nrow(Carseats),300) #get 300 for trainning
#2. Fit a regression tree to the training set. Plot the tree, and interpret the results.
#What test MSE do you obtain?
car.tree = tree(Sales~., data = Carseats[train,])
plot(car.tree)
text(car.tree, pretty = 0)
summary(car.tree)
predTree  = predict(car.tree, newdata = Carseats[-train,])
mean( (predTree - Carseats[-train,]$Sales)^2 ) #test MSE
#3. Use cross-validation in order to determine the optimal level of tree complexity.
# Does pruning the tree improve the test MSE? NO
cv.carTree = cv.tree(car.tree, FUN = prune.tree)
plot(cv.carTree)
cv.carTree
#prune.tree  = prune.tree(car.tree, best = 15)
prune.tree  = prune.tree(car.tree, best = 8)
predPrune  = predict(prune.tree, newdata = Carseats[-train,])
mean( (predPrune - Carseats[-train,]$Sales)^2 ) #test MSE
#4. Use the bagging approach in order to analyze this data. What test MSE do you
#obtain? Use the importance() function to determine which variables are most important
bg.cars = randomForest(Sales~., data = Carseats[train,], importance = TRUE, mtry = 11)
bg.cars$importance
bg.pred = predict(bg.cars, newdata = Carseats[-train,])
mean((bg.pred - Carseats[-train,]$Sales)^2)
#5. Use random forests to analyze this data. What test MSE do you obtain? Use the
#importance() function to determine which variables are most important. Describe the
#effect of m, the number of variables considered at each split, on the error rate obtained.
rf.cars = randomForest(Sales~., data = Carseats[train,], mtry =4 ,importance = TRUE)
rf.cars$importance
rf.pred = predict(rf.cars, newdata = Carseats[-train,])
mean((rf.pred - Carseats[-train,]$Sales)^2)
# By selecting a differente number of variables for the splits random forest manages to decorrale the trees
# this results in a lower error.
ncol(Carseats)
library(ISLR)
require(tree)
#install.packages("randomForest")
require(randomForest)
#1. Split the data set into a training set and a test set.
attach(Carseats)
set.seed(20)
train = sample(1:nrow(Carseats),300) #get 300 for trainning
#2. Fit a regression tree to the training set. Plot the tree, and interpret the results.
#What test MSE do you obtain?
car.tree = tree(Sales~., data = Carseats[train,])
plot(car.tree)
text(car.tree, pretty = 0)
summary(car.tree)
predTree  = predict(car.tree, newdata = Carseats[-train,])
mean( (predTree - Carseats[-train,]$Sales)^2 ) #test MSE
#3. Use cross-validation in order to determine the optimal level of tree complexity.
# Does pruning the tree improve the test MSE? NO
cv.carTree = cv.tree(car.tree, FUN = prune.tree)
plot(cv.carTree)
cv.carTree
#prune.tree  = prune.tree(car.tree, best = 15)
prune.tree  = prune.tree(car.tree, best = 8)
predPrune  = predict(prune.tree, newdata = Carseats[-train,])
mean( (predPrune - Carseats[-train,]$Sales)^2 ) #test MSE
#4. Use the bagging approach in order to analyze this data. What test MSE do you
#obtain? Use the importance() function to determine which variables are most important
bg.cars = randomForest(Sales~., data = Carseats[train,], importance = TRUE, mtry = 10)
bg.cars$importance
bg.pred = predict(bg.cars, newdata = Carseats[-train,])
mean((bg.pred - Carseats[-train,]$Sales)^2)
#5. Use random forests to analyze this data. What test MSE do you obtain? Use the
#importance() function to determine which variables are most important. Describe the
#effect of m, the number of variables considered at each split, on the error rate obtained.
rf.cars = randomForest(Sales~., data = Carseats[train,], mtry = 3 ,importance = TRUE)
rf.cars$importance
rf.pred = predict(rf.cars, newdata = Carseats[-train,])
mean((rf.pred - Carseats[-train,]$Sales)^2)
# By selecting a differente number of variables for the splits random forest manages to decorrale the trees
# this results in a lower error.
rf.cars = randomForest(Sales~., data = Carseats[train,], mtry = 4 ,importance = TRUE)
rf.cars$importance
rf.pred = predict(rf.cars, newdata = Carseats[-train,])
mean((rf.pred - Carseats[-train,]$Sales)^2)
rm(list = ls())
source('~/RIT/KDD/Lab5/lab5_1.R', echo=TRUE)
require(tree)
#1. Create a training set containing a random sample of 800 observations, and a test
#set containing the remaining observations.
attach(OJ)
source('~/RIT/KDD/Lab5/lab5_1.R', echo=TRUE)
rm(list = ls())
#libraries
#install.packages("glmnet")
library(glmnet)
#set working directory
setwd("~/RIT/KDD/Lab4")
#read data
college = read.csv("College.csv", header = TRUE,na.strings = "?")
college = college[,-1]
attach(college)
#1. Split the data set into a training set and a test set.
train = college[1:500,]
test = college[501:777,]
#2. Fit a linear model using least squares on the training set, and report the test error
#obtained.
lm.fit = lm(Apps~ ., data = train)
pred = predict(lm.fit,newdata = test, se.fit = TRUE)
summary(lm.fit)
mean((pred$fit - test$Apps)^2) #error of predictions.
pred$residual.scale #standard
#3)Fit a ridge regression model on the training set, with λ chosen by cross-validation.
#Report the test error obtained
#ridge = glmnet()
x = model.matrix(Apps~.-1, data = train) #if you type what you want to predict and put a -1 it removes it form the model
y = train$Apps # response or what I want to predict
ridge = glmnet(x, y, alpha = 0)
plot(ridge, xvar = "lambda", label = TRUE) # checking the coefficients
cv.ridge = cv.glmnet(x, y, alpha=0)
plot(cv.ridge)
bestLambda = cv.ridge$lambda.min # getting best lambda
ridge.pred = predict(ridge, s= bestLambda , newx = model.matrix(Apps~.-1, data = test))
mean((ridge.pred- test$Apps)^2)
#4. Fit a lasso model on the training set, with λ chosen by cross-validation. Report the
#test error obtained, along with the number of non-zero coefficient estimates.
lasso = glmnet(x, y, alpha = 1)
plot(lasso, xvar = "lambda", label = TRUE) # checking the coefficients
set.seed(1)
cv.lasso = cv.glmnet(x, y, alpha=1)
plot(cv.lasso)
bestLambda2 = cv.lasso$lambda.min
lasso.pred = predict(lasso, s= bestLambda2 ,newx = model.matrix(Apps~.-1, data = test))
mean((lasso.pred- test$Apps)^2)
#5. Comment on the results obtained. How accurately can we predict the number of college
#applications received? Is there much difference among the test errors resulting from these five approaches?
#This lasso regression provies the smaller error and also is not using all the predictors, given the fact tha
# | Bj | can make coefficiente zero when lambda is big enough, so we end up using only 4 predictors.
?prcomp
?var
states=row.names(USArrests)
states
names(USArrests)
apply(USArrests, 2, mean)
apply(USArrests, 2, var)
pr.out=prcomp(USArrests, scale=TRUE)
names(pr.out)
pr.out$center
pr.out$scale
pr.out$rotation
dim(pr.out$x)
biplot(pr.out, scale=0)
pr.out$rotation=-pr.out$rotation
pr.out$x=-pr.out$x
biplot(pr.out, scale=0)
pr.out$sdev
pr.var=pr.out$sdev^2
pr.var
pve=pr.var/sum(pr.var)
pve
plot(pve, xlab="Principal Component", ylab="Proportion of Variance Explained", ylim=c(0,1),type='b')
plot(cumsum(pve), xlab="Principal Component", ylab="Cumulative Proportion of Variance Explained", ylim=c(0,1),type='b')
a=c(1,2,8,-3)
cumsum(a)
states=row.names(USArrests)
states
names(USArrests)
apply(USArrests, 2, mean)
apply(USArrests, 2, var)
pr.out=prcomp(USArrests, scale=TRUE)
names(pr.out)
pr.out$center
pr.out$scale
pr.out$rotation
dim(pr.out$x)
biplot(pr.out, scale=0)
pr.out$rotation=-pr.out$rotation
pr.out$x=-pr.out$x
biplot(pr.out, scale=0)
pr.out$sdev
pr.var=pr.out$sdev^2
pr.var
pve=pr.var/sum(pr.var)
pve
plot(pve, xlab="Principal Component", ylab="Proportion of Variance Explained", ylim=c(0,1),type='b')
?cumsum
?glm
